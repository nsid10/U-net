{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"EffUnet_training_v1.ipynb","provenance":[],"collapsed_sections":[],"machine_shape":"hm"},"kernelspec":{"display_name":"Python 3","name":"python3"}},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"srj2HS8CY378","executionInfo":{"status":"ok","timestamp":1612845071412,"user_tz":360,"elapsed":1279,"user":{"displayName":"Nahian Siddique","photoUrl":"","userId":"05396263425142465889"}},"outputId":"c0177dd6-8d3f-49a7-f87b-bd23d8e24c2e"},"source":["from google.colab import drive\n","\n","drive.mount(\"/content/gdrive\", force_remount=True)"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Mounted at /content/gdrive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"E5IlsIDpbufV","executionInfo":{"status":"ok","timestamp":1612845074028,"user_tz":360,"elapsed":3884,"user":{"displayName":"Nahian Siddique","photoUrl":"","userId":"05396263425142465889"}},"outputId":"4a494571-cf14-4a87-fd99-0417f103d189"},"source":["pip install efficientnet"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: efficientnet in /usr/local/lib/python3.6/dist-packages (1.1.1)\n","Requirement already satisfied: scikit-image in /usr/local/lib/python3.6/dist-packages (from efficientnet) (0.16.2)\n","Requirement already satisfied: keras-applications<=1.0.8,>=1.0.7 in /usr/local/lib/python3.6/dist-packages (from efficientnet) (1.0.8)\n","Requirement already satisfied: imageio>=2.3.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image->efficientnet) (2.4.1)\n","Requirement already satisfied: networkx>=2.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image->efficientnet) (2.5)\n","Requirement already satisfied: matplotlib!=3.0.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image->efficientnet) (3.2.2)\n","Requirement already satisfied: scipy>=0.19.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image->efficientnet) (1.4.1)\n","Requirement already satisfied: pillow>=4.3.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image->efficientnet) (7.0.0)\n","Requirement already satisfied: PyWavelets>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image->efficientnet) (1.1.1)\n","Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.6/dist-packages (from keras-applications<=1.0.8,>=1.0.7->efficientnet) (1.19.5)\n","Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications<=1.0.8,>=1.0.7->efficientnet) (2.10.0)\n","Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.6/dist-packages (from networkx>=2.0->scikit-image->efficientnet) (4.4.2)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->efficientnet) (0.10.0)\n","Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->efficientnet) (2.8.1)\n","Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->efficientnet) (2.4.7)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->efficientnet) (1.3.1)\n","Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from h5py->keras-applications<=1.0.8,>=1.0.7->efficientnet) (1.15.0)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"r5-9Gueojnuw","executionInfo":{"status":"ok","timestamp":1612845075959,"user_tz":360,"elapsed":5807,"user":{"displayName":"Nahian Siddique","photoUrl":"","userId":"05396263425142465889"}}},"source":["import datetime\n","import os\n","import numpy as np\n","import tensorflow as tf\n","\n","from efficientnet.keras import EfficientNetB4, EfficientNetB5, EfficientNetB6, EfficientNetB7\n","from keras import backend as K\n","from tensorflow.keras.layers import Activation, Add, BatchNormalization, concatenate, Conv2D, Conv2DTranspose\n","from tensorflow.keras.layers import Dropout, LeakyReLU, MaxPooling2D\n","from tensorflow.keras.optimizers import Adam\n","from tensorflow.keras.regularizers import l2"],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"id":"fdeN95zBjutg","executionInfo":{"status":"ok","timestamp":1612845075965,"user_tz":360,"elapsed":5807,"user":{"displayName":"Nahian Siddique","photoUrl":"","userId":"05396263425142465889"}}},"source":["np.random.seed = 1\r\n","\r\n","dataset = \"DRIVE\"\r\n","\r\n","main_path = f\"/content/gdrive/My Drive/Data/{dataset}\""],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"id":"hzXSBdP4kE8_","executionInfo":{"status":"ok","timestamp":1612845075966,"user_tz":360,"elapsed":5803,"user":{"displayName":"Nahian Siddique","photoUrl":"","userId":"05396263425142465889"}}},"source":["training_images = f\"{main_path}/patches/images/train/\"\n","training_labels = f\"{main_path}/patches/labels/train/\"\n","\n","train_img = next(os.walk(training_images))[2]\n","train_lbs = next(os.walk(training_labels))[2]\n","\n","train_img.sort()\n","train_lbs.sort()"],"execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"id":"srTlne2cgaav","executionInfo":{"status":"ok","timestamp":1612845090443,"user_tz":360,"elapsed":20274,"user":{"displayName":"Nahian Siddique","photoUrl":"","userId":"05396263425142465889"}}},"source":["X_train = np.concatenate([np.load(training_images + file_id)[\"arr_0\"] for file_id in train_img], axis=0)\r\n","Y_train = np.concatenate([np.load(training_labels + file_id)[\"arr_0\"] for file_id in train_lbs], axis=0)\r\n","\r\n","X_train = X_train / 255\r\n","Y_train = Y_train / 255"],"execution_count":6,"outputs":[]},{"cell_type":"code","metadata":{"id":"oP10iUrbAtyy","executionInfo":{"status":"ok","timestamp":1612845090443,"user_tz":360,"elapsed":20269,"user":{"displayName":"Nahian Siddique","photoUrl":"","userId":"05396263425142465889"}}},"source":["# Y_train = Y_train.astype(\"float64\")"],"execution_count":7,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0AeWgduh8ieQ","executionInfo":{"status":"ok","timestamp":1612845092677,"user_tz":360,"elapsed":22496,"user":{"displayName":"Nahian Siddique","photoUrl":"","userId":"05396263425142465889"}},"outputId":"88319f06-e8dc-40a0-a36b-e42b36f0474d"},"source":["print(np.max(X_train))\r\n","print(np.min(X_train))\r\n","print(np.max(Y_train))\r\n","print(np.min(Y_train))"],"execution_count":8,"outputs":[{"output_type":"stream","text":["1.0\n","0.0\n","1.0\n","0.0\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JR_8TGXyyYNT","executionInfo":{"status":"ok","timestamp":1612845092677,"user_tz":360,"elapsed":22488,"user":{"displayName":"Nahian Siddique","photoUrl":"","userId":"05396263425142465889"}},"outputId":"fbaf6e55-12c0-40ff-82a1-c835374a2008"},"source":["X_train.shape"],"execution_count":9,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(80000, 64, 64, 3)"]},"metadata":{"tags":[]},"execution_count":9}]},{"cell_type":"code","metadata":{"id":"db6MGxGNam4w","executionInfo":{"status":"ok","timestamp":1612845092678,"user_tz":360,"elapsed":22482,"user":{"displayName":"Nahian Siddique","photoUrl":"","userId":"05396263425142465889"}}},"source":["_, h, w, c = X_train.shape\n","\n","input_shape = (h, w, c)"],"execution_count":10,"outputs":[]},{"cell_type":"code","metadata":{"id":"C1Ctbt0QcSJY","executionInfo":{"status":"ok","timestamp":1612845092678,"user_tz":360,"elapsed":22477,"user":{"displayName":"Nahian Siddique","photoUrl":"","userId":"05396263425142465889"}}},"source":["def residual_block(x, filters):\n","    y = Conv2D(filters, (3, 3), strides=(1, 1), padding=\"same\")(x)\n","    y = LeakyReLU(alpha=0)(y)\n","    y = BatchNormalization()(y)\n","\n","    y = Conv2D(filters, (3, 3), strides=(1, 1), padding=\"same\")(y)\n","    y = LeakyReLU(alpha=0)(y)\n","    y = BatchNormalization()(y)\n","\n","    out = Add()([x, y])\n","    return out"],"execution_count":11,"outputs":[]},{"cell_type":"code","metadata":{"id":"I3iSmK5uPBEU","executionInfo":{"status":"ok","timestamp":1612845092679,"user_tz":360,"elapsed":22472,"user":{"displayName":"Nahian Siddique","photoUrl":"","userId":"05396263425142465889"}}},"source":["def reccurent_block(x, filters, a=0):\n","    bn_axis = 3\n","\n","    x1 = Conv2D(filters, (3, 3), strides=(1, 1), padding=\"same\")(x)\n","    x1 = LeakyReLU(alpha=a)(x1)\n","\n","    x2 = Conv2D(filters, (3, 3), strides=(1, 1), padding=\"same\")(x1)              \n","    x2 = LeakyReLU(alpha=a)(x2)\n","    x12 = Add()([x1, x2])\n","\n","    x3 = Conv2D(filters, (3, 3), strides=(1, 1), padding=\"same\")(x12) \n","    x3 = LeakyReLU(alpha=a)(x3)\n","    x13 = Add()([x1, x3])\n","\n","    x4 = Conv2D(filters, (3, 3), strides=(1, 1), padding=\"same\")(x13)\n","    x4 = LeakyReLU(alpha=a)(x4)\n","    x14 = Add()([x1, x4])\n","\n","    x = LeakyReLU(alpha=a)(x14)\n","    x = BatchNormalization()(x)\n","    return x"],"execution_count":12,"outputs":[]},{"cell_type":"code","metadata":{"id":"JQFIMflla15N","executionInfo":{"status":"ok","timestamp":1612845092729,"user_tz":360,"elapsed":22516,"user":{"displayName":"Nahian Siddique","photoUrl":"","userId":"05396263425142465889"}}},"source":["def efficientB4ResUnet(input_shape):\n","    encoder = EfficientNetB4(include_top=False, weights=\"imagenet\", input_shape=input_shape)\n","\n","    # contracting level 4\n","    input = encoder.input\n","    en4 = Conv2D(24, (3, 3), strides=(1, 1), padding=\"same\", activation=None)(input)\n","    en4 = LeakyReLU(alpha=0)(en4)\n","    en4 = BatchNormalization()(en4)\n","\n","    # contracting level 3\n","    en3 = encoder.layers[25].output\n","\n","    # contracting level 2\n","    en2 = encoder.layers[83].output\n","\n","    # contracting level 1\n","    en1 = encoder.layers[141].output\n","\n","    # middle level 0\n","    en0 = encoder.layers[317].output\n","    cv0 = residual_block(en0, 160)\n","    cv0 = residual_block(cv0, 160)\n","    up0 = Conv2DTranspose(56, (2, 2), strides=(2, 2), padding=\"same\", name=\"upconvolution_1\")(cv0)\n","\n","    # expandsion level 1\n","    cv1 = concatenate([up0, en1])\n","    cv1 = residual_block(cv1, 112)\n","    up1 = Conv2DTranspose(32, (2, 2), strides=(2, 2), padding=\"same\", name=\"upconvolution_2\")(cv1)\n","\n","    # expandsion level 2\n","    cv2 = concatenate([up1, en2])\n","    cv2 = residual_block(cv2, 64)\n","    up2 = Conv2DTranspose(24, (2, 2), strides=(2, 2), padding=\"same\", name=\"upconvolution_3\")(cv2)\n","\n","    # expandsion level 3\n","    cv3 = concatenate([up2, en3])\n","    cv3 = residual_block(cv3, 48)\n","    up3 = Conv2DTranspose(24, (2, 2), strides=(2, 2), padding=\"same\", name=\"upconvolution_4\")(cv3)\n","\n","    # expandsion level 4\n","    cv4 = concatenate([up3, en4])\n","    cv4 = residual_block(cv4, 48)\n","\n","    out = Conv2D(1, (1, 1), activation=\"sigmoid\")(cv4)\n","\n","    model = tf.keras.Model(inputs=[input], outputs=[out])\n","    model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n","\n","    return model"],"execution_count":13,"outputs":[]},{"cell_type":"code","metadata":{"id":"0Z_FXstld1B_","executionInfo":{"status":"ok","timestamp":1612845092729,"user_tz":360,"elapsed":22507,"user":{"displayName":"Nahian Siddique","photoUrl":"","userId":"05396263425142465889"}}},"source":["def efficientB5ResUnet(input_shape):\n","    encoder = EfficientNetB5(include_top=False, weights=\"imagenet\", input_shape=input_shape)\n","\n","    # contracting level 4\n","    input = encoder.input\n","    en4 = Conv2D(24, (3, 3), strides=(1, 1), padding=\"same\", activation=None)(input)\n","    en4 = LeakyReLU(alpha=0)(en4)\n","    en4 = BatchNormalization()(en4)\n","\n","    # contracting level 3\n","    en3 = encoder.layers[37].output\n","\n","    # contracting level 2\n","    en2 = encoder.layers[110].output\n","\n","    # contracting level 1\n","    en1 = encoder.layers[183].output\n","\n","    # middle level 0\n","    en0 = encoder.layers[389].output\n","    cv0 = residual_block(en0, 176)\n","    cv0 = residual_block(cv0, 176)\n","    up0 = Conv2DTranspose(64, (2, 2), strides=(2, 2), padding=\"same\", name=\"upconvolution_1\")(cv0)\n","\n","    # expandsion level 1\n","    cv1 = concatenate([up0, en1])\n","    cv1 = residual_block(cv1, 128)\n","    up1 = Conv2DTranspose(40, (2, 2), strides=(2, 2), padding=\"same\", name=\"upconvolution_2\")(cv1)\n","\n","    # expandsion level 2\n","    cv2 = concatenate([up1, en2])\n","    cv2 = residual_block(cv2, 80)\n","    up2 = Conv2DTranspose(24, (2, 2), strides=(2, 2), padding=\"same\", name=\"upconvolution_3\")(cv2)\n","\n","    # expandsion level 3\n","    cv3 = concatenate([up2, en3])\n","    cv3 = residual_block(cv3, 48)\n","    up3 = Conv2DTranspose(24, (2, 2), strides=(2, 2), padding=\"same\", name=\"upconvolution_4\")(cv3)\n","\n","    # expandsion level 4\n","    cv4 = concatenate([up3, en4])\n","    cv4 = residual_block(cv4, 48)\n","\n","    out = Conv2D(1, (1, 1), activation=\"sigmoid\")(cv4)\n","\n","    model = tf.keras.Model(inputs=[input], outputs=[out])\n","    model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n","\n","    return model"],"execution_count":14,"outputs":[]},{"cell_type":"code","metadata":{"id":"wr6yxvHR_bYn","executionInfo":{"status":"ok","timestamp":1612845092883,"user_tz":360,"elapsed":22653,"user":{"displayName":"Nahian Siddique","photoUrl":"","userId":"05396263425142465889"}}},"source":["def efficientB6ResUnet(input_shape):\r\n","    encoder = EfficientNetB6(include_top=False, weights=\"imagenet\", input_shape=input_shape)\r\n","\r\n","    # contracting level 4\r\n","    input = encoder.input\r\n","    en4 = Conv2D(32, (3, 3), strides=(1, 1), padding=\"same\", activation=None)(input)\r\n","    en4 = LeakyReLU(alpha=0)(en4)\r\n","    en4 = BatchNormalization()(en4)\r\n","\r\n","    # contracting level 3\r\n","    en3 = encoder.layers[37].output\r\n","\r\n","    # contracting level 2\r\n","    en2 = encoder.layers[125].output\r\n","\r\n","    # contracting level 1\r\n","    en1 = encoder.layers[213].output\r\n","\r\n","    # middle level 0\r\n","    en0 = encoder.layers[449].output\r\n","    cv0 = residual_block(en0, 200)\r\n","    cv0 = residual_block(cv0, 200)\r\n","    up0 = Conv2DTranspose(72, (2, 2), strides=(2, 2), padding=\"same\", name=\"upconvolution_1\")(cv0)\r\n","\r\n","    # expandsion level 1\r\n","    cv1 = concatenate([up0, en1])\r\n","    cv1 = residual_block(cv1, 144)\r\n","    up1 = Conv2DTranspose(40, (2, 2), strides=(2, 2), padding=\"same\", name=\"upconvolution_2\")(cv1)\r\n","\r\n","    # expandsion level 2\r\n","    cv2 = concatenate([up1, en2])\r\n","    cv2 = residual_block(cv2, 80)\r\n","    up2 = Conv2DTranspose(32, (2, 2), strides=(2, 2), padding=\"same\", name=\"upconvolution_3\")(cv2)\r\n","\r\n","    # expandsion level 3\r\n","    cv3 = concatenate([up2, en3])\r\n","    cv3 = residual_block(cv3, 64)\r\n","    up3 = Conv2DTranspose(32, (2, 2), strides=(2, 2), padding=\"same\", name=\"upconvolution_4\")(cv3)\r\n","\r\n","    # expandsion level 4\r\n","    cv4 = concatenate([up3, en4])\r\n","    cv4 = residual_block(cv4, 64)\r\n","\r\n","    out = Conv2D(1, (1, 1), activation=\"sigmoid\")(cv4)\r\n","\r\n","    model = tf.keras.Model(inputs=[input], outputs=[out])\r\n","    model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\r\n","\r\n","    return model"],"execution_count":15,"outputs":[]},{"cell_type":"code","metadata":{"id":"qPGG86AsPT13","executionInfo":{"status":"ok","timestamp":1612845092884,"user_tz":360,"elapsed":22648,"user":{"displayName":"Nahian Siddique","photoUrl":"","userId":"05396263425142465889"}}},"source":["def efficientB6R2Unet(input_shape):\n","    a = 0\n","\n","    encoder = EfficientNetB6(include_top=False, weights=\"imagenet\", input_shape=input_shape)\n","\n","    # contracting level 4\n","    input = encoder.input\n","    en4 = Conv2D(32, (3, 3), strides=(1, 1), padding=\"same\", activation=None)(input)\n","    en4 = LeakyReLU(alpha=a)(en4)\n","    en4 = BatchNormalization()(en4)\n","\n","    # contracting level 3\n","    en3 = encoder.layers[37].output\n","\n","    # contracting level 2\n","    en2 = encoder.layers[125].output\n","\n","    # contracting level 1\n","    en1 = encoder.layers[213].output\n","\n","    # middle level 0\n","    en0 = encoder.layers[449].output\n","    cv0 = reccurent_block(en0, 200, a)\n","    up0 = Conv2DTranspose(200, (2, 2), strides=(2, 2), padding=\"same\", name=\"upconvolution_1\")(cv0)\n","\n","    # expandsion level 1\n","    cv1 = concatenate([up0, en1])\n","    cv1 = reccurent_block(cv1, 144, a)\n","    up1 = Conv2DTranspose(144, (2, 2), strides=(2, 2), padding=\"same\", name=\"upconvolution_2\")(cv1)\n","\n","    # expandsion level 2\n","    cv2 = concatenate([up1, en2])\n","    cv2 = reccurent_block(cv2, 80, a)\n","    up2 = Conv2DTranspose(80, (2, 2), strides=(2, 2), padding=\"same\", name=\"upconvolution_3\")(cv2)\n","\n","    # expandsion level 3\n","    cv3 = concatenate([up2, en3])\n","    cv3 = reccurent_block(cv3, 64, a)\n","    up3 = Conv2DTranspose(64, (2, 2), strides=(2, 2), padding=\"same\", name=\"upconvolution_4\")(cv3)\n","\n","    # expandsion level 4\n","    cv4 = concatenate([up3, en4])\n","    cv4 = reccurent_block(cv4, 32, a)\n","\n","    out = Conv2D(1, (1, 1), activation=\"sigmoid\")(cv4)\n","\n","    model = tf.keras.Model(inputs=[input], outputs=[out])\n","    model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n","\n","    return model"],"execution_count":16,"outputs":[]},{"cell_type":"code","metadata":{"id":"2QBCxnEM88bU","executionInfo":{"status":"ok","timestamp":1612845092884,"user_tz":360,"elapsed":22643,"user":{"displayName":"Nahian Siddique","photoUrl":"","userId":"05396263425142465889"}}},"source":["def efficientB7R2Unet(input_shape):\r\n","    a = 0\r\n","\r\n","    encoder = EfficientNetB7(include_top=False, weights=\"imagenet\", input_shape=input_shape)\r\n","\r\n","    # contracting level 4\r\n","    input = encoder.input\r\n","    en4 = reccurent_block(input, 32, a)\r\n","\r\n","    # contracting level 3\r\n","    en3 = encoder.layers[49].output\r\n","\r\n","    # contracting level 2\r\n","    en2 = encoder.layers[152].output\r\n","\r\n","    # contracting level 1\r\n","    en1 = encoder.layers[255].output\r\n","\r\n","    # middle level 0\r\n","    en0 = encoder.layers[551].output\r\n","    cv0 = reccurent_block(en0, 224, a)\r\n","    up0 = Conv2DTranspose(224, (2, 2), strides=(2, 2), padding=\"same\", name=\"upconvolution_1\")(cv0)\r\n","\r\n","    # expandsion level 1\r\n","    cv1 = concatenate([up0, en1])\r\n","    cv1 = reccurent_block(cv1, 160, a)\r\n","    up1 = Conv2DTranspose(160, (2, 2), strides=(2, 2), padding=\"same\", name=\"upconvolution_2\")(cv1)\r\n","\r\n","    # expandsion level 2\r\n","    cv2 = concatenate([up1, en2])\r\n","    cv2 = reccurent_block(cv2, 96, a)\r\n","    up2 = Conv2DTranspose(96, (2, 2), strides=(2, 2), padding=\"same\", name=\"upconvolution_3\")(cv2)\r\n","\r\n","    # expandsion level 3\r\n","    cv3 = concatenate([up2, en3])\r\n","    cv3 = reccurent_block(cv3, 64, a)\r\n","    up3 = Conv2DTranspose(64, (2, 2), strides=(2, 2), padding=\"same\", name=\"upconvolution_4\")(cv3)\r\n","\r\n","    # expandsion level 4\r\n","    cv4 = concatenate([up3, en4])\r\n","    cv4 = reccurent_block(cv4, 32, a)\r\n","\r\n","    out = Conv2D(1, (1, 1), activation=\"sigmoid\")(cv4)\r\n","\r\n","    model = tf.keras.Model(inputs=[input], outputs=[out])\r\n","    model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\r\n","\r\n","    return model"],"execution_count":17,"outputs":[]},{"cell_type":"code","metadata":{"id":"mfevAUD_8UOG","executionInfo":{"status":"ok","timestamp":1612845092885,"user_tz":360,"elapsed":22638,"user":{"displayName":"Nahian Siddique","photoUrl":"","userId":"05396263425142465889"}}},"source":["from tensorflow.keras.layers import Flatten"],"execution_count":18,"outputs":[]},{"cell_type":"code","metadata":{"id":"jR-I_Mh553SB","executionInfo":{"status":"ok","timestamp":1612845092963,"user_tz":360,"elapsed":22711,"user":{"displayName":"Nahian Siddique","photoUrl":"","userId":"05396263425142465889"}}},"source":["# Metric function\n","def dice_coef(y_true, y_pred):\n","    smooth = 1\n","    y_true_f = Flatten(y_true)\n","    y_pred_f = Flatten(y_pred)\n","    intersection = np.sum(y_true_f * y_pred_f)\n","    return (2.0 * intersection + smooth) / (np.sum(y_true_f) + np.sum(y_pred_f) + smooth)\n","\n","\n","# Loss funtion\n","def dice_coef_loss(y_true, y_pred):\n","    return -dice_coef(y_true, y_pred)"],"execution_count":19,"outputs":[]},{"cell_type":"code","metadata":{"id":"fpq20TdW40UF","executionInfo":{"status":"ok","timestamp":1612845092964,"user_tz":360,"elapsed":22706,"user":{"displayName":"Nahian Siddique","photoUrl":"","userId":"05396263425142465889"}}},"source":["def Rec_conv2d_bn(x, n_filter, nb_row, nb_col, border_mode=\"same\", strides=(1, 1)):\n","    \"\"\"Utility function to apply conv + BN.\"\"\"\n","\n","    # if K.image_dim_ordering() == 'tf':\n","    bn_axis = 3\n","\n","    x1 = Conv2D(n_filter, (nb_row, nb_col), strides=strides, padding=border_mode, kernel_regularizer=l2(2e-3))(x)\n","    x1 = Activation(\"relu\")(x1)\n","\n","    x2 = Conv2D(n_filter, (nb_row, nb_col), strides=strides, padding=border_mode, kernel_regularizer=l2(2e-3))(x1)\n","    x2 = Activation(\"relu\")(x2)\n","    x12 = Add()([x1, x2])\n","\n","    x3 = Conv2D(n_filter, (nb_row, nb_col), strides=strides, padding=border_mode, kernel_regularizer=l2(2e-3))(x12)\n","    x3 = Activation(\"relu\")(x3)\n","    x13 = Add()([x1, x3])\n","\n","    x4 = Conv2D(n_filter, (nb_row, nb_col), strides=strides, padding=\"same\", kernel_regularizer=l2(2e-3))(x13)\n","    x4 = Activation(\"relu\")(x4)\n","\n","    x14 = Add()([x1, x4])\n","\n","    x = Activation(\"relu\")(x14)\n","\n","    x = BatchNormalization(axis=bn_axis)(x13)\n","    return x"],"execution_count":20,"outputs":[]},{"cell_type":"code","metadata":{"id":"1ZzyUsrF4015","executionInfo":{"status":"ok","timestamp":1612845093063,"user_tz":360,"elapsed":22800,"user":{"displayName":"Nahian Siddique","photoUrl":"","userId":"05396263425142465889"}}},"source":["def build_R2UNetED(input_shape):\n","\n","    channel_axis = 3\n","    inputs = tf.keras.Input(input_shape)\n","\n","    # first block\n","    x = Conv2D(32, (3, 3), activation=\"relu\", padding=\"same\")(inputs)\n","    rcnn_bn1 = Rec_conv2d_bn(x, 32, 3, 3)\n","    conv1_f = Add()([x, rcnn_bn1])\n","    pool1 = MaxPooling2D((2, 2))(conv1_f)\n","    conv_pool1 = Conv2D(64, (1, 1), activation=\"relu\", padding=\"same\")(pool1)\n","\n","    # second RRCNN layer...\n","    rcnn_bn2 = Rec_conv2d_bn(conv_pool1, 64, 3, 3)\n","    conv2_f = Add()([conv_pool1, rcnn_bn2])\n","    pool2 = MaxPooling2D((2, 2))(conv2_f)\n","    conv_pool2 = Conv2D(128, (1, 1), activation=\"relu\", padding=\"same\")(pool2)\n","\n","    # third RRCNN layer...\n","    rcnn_bn3 = Rec_conv2d_bn(conv_pool2, 128, 3, 3)\n","    conv3_f = Add()([conv_pool2, rcnn_bn3])\n","    pool3 = MaxPooling2D((2, 2))(conv3_f)\n","    conv_pool3 = Conv2D(256, (1, 1), activation=\"relu\", padding=\"same\")(pool3)\n","\n","    # fourth RRCNN layer...\n","    rcnn_bn4 = Rec_conv2d_bn(conv_pool3, 256, 3, 3)\n","    conv4_f = Add()([conv_pool3, rcnn_bn4])\n","\n","    # Decoder...\n","\n","    up7_1 = Conv2DTranspose(128, (3, 3), strides=(2, 2), padding=\"same\")(conv4_f)\n","    up7 = concatenate([up7_1, conv3_f], axis=channel_axis)\n","    up7 = Rec_conv2d_bn(up7, 128, 3, 3)\n","    conv7 = Conv2D(128, (3, 3), activation=\"relu\", padding=\"same\")(up7)\n","    # conv7 = Conv2D(128, (3, 3), activation=\"relu\", padding=\"same\")(conv7)\n","\n","    up8_1 = Conv2DTranspose(64, (3, 3), strides=(2, 2), padding=\"same\")(conv7)\n","    up8 = concatenate([up8_1, conv2_f], axis=channel_axis)\n","    up8 = Rec_conv2d_bn(up8, 128, 3, 3)\n","    conv8 = Conv2D(64, (3, 3), activation=\"relu\", padding=\"same\")(up8)\n","    # conv8 = Conv2D(64, (3, 3), activation=\"relu\", padding=\"same\")(conv8)\n","\n","    up9_1 = Conv2DTranspose(32, (3, 3), strides=(2, 2), padding=\"same\")(conv8)\n","    up9 = concatenate([up9_1, conv1_f], axis=channel_axis)\n","    up9 = Rec_conv2d_bn(up9, 128, 3, 3)\n","    conv9 = Conv2D(32, (3, 3), activation=\"relu\", padding=\"same\")(up9)\n","    # conv9 = Conv2D(32, (3, 3), activation=\"relu\", padding=\"same\")(conv9)\n","\n","    conv10 = Conv2D(1, (1, 1), activation=\"sigmoid\")(conv9)\n","\n","    model = tf.keras.Model(inputs=[inputs], outputs=[conv10])\n","\n","    # model.compile(optimizer=Adam(2e-4), loss=dice_coef_loss, metrics=[dice_coef, \"acc\", \"mse\"])\n","\n","    model.compile(optimizer=Adam(3e-4), loss='binary_crossentropy',metrics = ['acc', 'mse'])\n","\n","    return model"],"execution_count":21,"outputs":[]},{"cell_type":"code","metadata":{"id":"-Q_5Zkq3l1PX","executionInfo":{"status":"ok","timestamp":1612845093063,"user_tz":360,"elapsed":22794,"user":{"displayName":"Nahian Siddique","photoUrl":"","userId":"05396263425142465889"}}},"source":["depth = 7\n","blocks = \"R2\""],"execution_count":22,"outputs":[]},{"cell_type":"code","metadata":{"id":"JHoaW6NSPlZd","executionInfo":{"status":"ok","timestamp":1612845093064,"user_tz":360,"elapsed":22790,"user":{"displayName":"Nahian Siddique","photoUrl":"","userId":"05396263425142465889"}}},"source":["# if depth == 1:\n","#     model = efficientB1R2Unet(input_shape)\n","# elif depth == 4:\n","#     model = efficientB4R2Unet(input_shape)\n","# elif depth == 5:\n","    # model = efficientB5R2Unet(input_shape)\n","# elif depth == 6:\n","#     model = efficientB6R2Unet(input_shape)\n","# elif depth == 7:\n","#     model = efficientB7R2Unet(input_shape)"],"execution_count":23,"outputs":[]},{"cell_type":"code","metadata":{"id":"q1QvqSrP85g6","executionInfo":{"status":"ok","timestamp":1612845093064,"user_tz":360,"elapsed":22785,"user":{"displayName":"Nahian Siddique","photoUrl":"","userId":"05396263425142465889"}}},"source":["# model = build_R2UNetED(input_shape)"],"execution_count":24,"outputs":[]},{"cell_type":"code","metadata":{"id":"dIi7E7WuH8a3","executionInfo":{"status":"ok","timestamp":1612845136322,"user_tz":360,"elapsed":66036,"user":{"displayName":"Nahian Siddique","photoUrl":"","userId":"05396263425142465889"}}},"source":["model = tf.keras.models.load_model(f\"/content/gdrive/My Drive/NN Models/{dataset}/model_DRIVE_EffB7_R2_2021-02-09 04:15:41\")"],"execution_count":25,"outputs":[]},{"cell_type":"code","metadata":{"id":"-LLLv5m7jT_u","executionInfo":{"status":"ok","timestamp":1612845136325,"user_tz":360,"elapsed":66034,"user":{"displayName":"Nahian Siddique","photoUrl":"","userId":"05396263425142465889"}}},"source":["# K.set_value(model.optimizer.learning_rate, 0.0001)\r\n","# K.set_value(model.optimizer.learning_rate, 0.00003)\r\n","K.set_value(model.optimizer.learning_rate, 0.00001)\r\n","# K.set_value(model.optimizer.learning_rate, 0.000003)"],"execution_count":26,"outputs":[]},{"cell_type":"code","metadata":{"id":"Vc-doOB_ucHw","executionInfo":{"status":"ok","timestamp":1612845136325,"user_tz":360,"elapsed":66028,"user":{"displayName":"Nahian Siddique","photoUrl":"","userId":"05396263425142465889"}}},"source":["# model.summary()"],"execution_count":27,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"E7nGTgvTau-X","executionInfo":{"status":"ok","timestamp":1612847314746,"user_tz":360,"elapsed":2244443,"user":{"displayName":"Nahian Siddique","photoUrl":"","userId":"05396263425142465889"}},"outputId":"48744e6d-4b7b-4b60-be16-025545cb5308"},"source":["model.fit(x=X_train, y=Y_train, batch_size=128, epochs=10, verbose=2)"],"execution_count":28,"outputs":[{"output_type":"stream","text":["Epoch 1/10\n","625/625 - 237s - loss: 0.0016 - accuracy: 0.9994\n","Epoch 2/10\n","625/625 - 216s - loss: 0.0016 - accuracy: 0.9994\n","Epoch 3/10\n","625/625 - 216s - loss: 0.0016 - accuracy: 0.9994\n","Epoch 4/10\n","625/625 - 215s - loss: 0.0016 - accuracy: 0.9994\n","Epoch 5/10\n","625/625 - 215s - loss: 0.0016 - accuracy: 0.9994\n","Epoch 6/10\n","625/625 - 215s - loss: 0.0016 - accuracy: 0.9994\n","Epoch 7/10\n","625/625 - 215s - loss: 0.0016 - accuracy: 0.9994\n","Epoch 8/10\n","625/625 - 215s - loss: 0.0016 - accuracy: 0.9994\n","Epoch 9/10\n","625/625 - 215s - loss: 0.0016 - accuracy: 0.9994\n","Epoch 10/10\n","625/625 - 215s - loss: 0.0016 - accuracy: 0.9994\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["<tensorflow.python.keras.callbacks.History at 0x7f3c701439b0>"]},"metadata":{"tags":[]},"execution_count":28}]},{"cell_type":"code","metadata":{"id":"TlD63jSpkN1_","executionInfo":{"status":"ok","timestamp":1612847314747,"user_tz":360,"elapsed":2244437,"user":{"displayName":"Nahian Siddique","photoUrl":"","userId":"05396263425142465889"}}},"source":["# model.save(f\"/content/gdrive/My Drive/NN Models/{dataset}/model_{dataset}_R2Unet_{str(datetime.datetime.now())[:-7]}\")"],"execution_count":29,"outputs":[]},{"cell_type":"code","metadata":{"id":"SjNCEiBT5be3","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1612847395323,"user_tz":360,"elapsed":2325008,"user":{"displayName":"Nahian Siddique","photoUrl":"","userId":"05396263425142465889"}},"outputId":"4814ce9e-b20b-45df-d628-0113085d7508"},"source":["model.save(f\"/content/gdrive/My Drive/NN Models/{dataset}/model_{dataset}_EffB{depth}_{blocks}_{str(datetime.datetime.now())[:-7]}\")"],"execution_count":30,"outputs":[{"output_type":"stream","text":["INFO:tensorflow:Assets written to: /content/gdrive/My Drive/NN Models/DRIVE/model_DRIVE_EffB7_R2_2021-02-09 05:08:34/assets\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"mfLeXdWaVUzM","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1612847395325,"user_tz":360,"elapsed":2325003,"user":{"displayName":"Nahian Siddique","photoUrl":"","userId":"05396263425142465889"}},"outputId":"c18a0595-5419-4e96-cdf6-cbe0d9a2285d"},"source":["print(\"\\n-----------------------------------------------End of process-----------------------------------------------\")"],"execution_count":31,"outputs":[{"output_type":"stream","text":["\n","-----------------------------------------------End of process-----------------------------------------------\n"],"name":"stdout"}]}]}